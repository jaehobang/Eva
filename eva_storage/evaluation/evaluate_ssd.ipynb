{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train, evaluate ssd on uadetrac and see how it performs in terms of precision and recall (unlabeled boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "## first let's load the data and corresponding boxes / labels for training\n",
    "\n",
    "%pylab inline\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.argv=['']\n",
    "sys.path.append('../../')\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import utils.helpers as helpers\n",
    "from loaders.uadetrac_loader import UADetracLoader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the data  \n",
    "loader = UADetracLoader()\n",
    "images = loader.load_cached_images()\n",
    "labels = loader.load_cached_labels()\n",
    "video_start_indices = loader.get_video_start_indices()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10421, 300, 300, 3)\n"
     ]
    }
   ],
   "source": [
    "print(images.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 664  936  437  784  800  800  906  694  800  800  800  800 1200]\n"
     ]
    }
   ],
   "source": [
    "print(video_start_indices)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Starting modification of train_ssd.py for ua-detrac\n",
    "## importing all relevant files\n",
    "import argparse\n",
    "import os\n",
    "import logging\n",
    "import sys\n",
    "import itertools\n",
    "import torch\n",
    "import config as jaeho_config\n",
    "from torch.utils.data import DataLoader, ConcatDataset\n",
    "from torch.optim.lr_scheduler import CosineAnnealingLR, MultiStepLR\n",
    "\n",
    "\n",
    "from eva_storage.external.ssd.vision.utils.misc import str2bool, Timer, freeze_net_layers, store_labels\n",
    "from eva_storage.external.ssd.vision.ssd.ssd import MatchPrior\n",
    "from eva_storage.external.ssd.vision.ssd.vgg_ssd import create_vgg_ssd\n",
    "from eva_storage.external.ssd.vision.ssd.mobilenetv1_ssd import create_mobilenetv1_ssd\n",
    "from eva_storage.external.ssd.vision.ssd.mobilenetv1_ssd_lite import create_mobilenetv1_ssd_lite\n",
    "from eva_storage.external.ssd.vision.ssd.mobilenet_v2_ssd_lite import create_mobilenetv2_ssd_lite\n",
    "from eva_storage.external.ssd.vision.ssd.squeezenet_ssd_lite import create_squeezenet_ssd_lite\n",
    "#from eva_storage.external.ssd.vision.datasets.voc_dataset import VOCDataset\n",
    "#from eva_storage.external.ssd.vision.datasets.open_images import OpenImagesDataset\n",
    "from eva_storage.external.ssd.vision.nn.multibox_loss import MultiboxLoss\n",
    "from eva_storage.external.ssd.vision.ssd.config import vgg_ssd_config\n",
    "from eva_storage.external.ssd.vision.ssd.config import mobilenetv1_ssd_config\n",
    "from eva_storage.external.ssd.vision.ssd.config import squeezenet_ssd_config\n",
    "from eva_storage.external.ssd.vision.ssd.data_preprocessing import TrainAugmentation, TestTransform\n",
    "\n",
    "\n",
    "\n",
    "DEVICE = torch.device(\"cuda:1\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "    torch.backends.cudnn.benchmark = True\n",
    "    logging.info(\"Use Cuda.\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_path = \"/home/jbang36/data/VOCdevkit/VOC2007\"\n",
    "#validation_path = \"/home/jbang36/data/VOCdevkit/VOC2007\"\n",
    "base_net = \"models/vgg16_reducedfc.pth\"\n",
    "batch_size = 24\n",
    "num_workers = 4\n",
    "num_epochs = 200\n",
    "checkpoint_folder = 'models/'\n",
    "lr = 1e-3\n",
    "momentum = 0.9\n",
    "weight_decay =5e-4\n",
    "validation_epochs = 5\n",
    "debug_steps = 100\n",
    "\n",
    "timer = Timer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_net' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-12-8292f165e86b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mnum_classes\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mnet\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_net\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnum_classes\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mmin_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m10000.0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mlast_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'create_net' is not defined"
     ]
    }
   ],
   "source": [
    "## Load the model\n",
    "\n",
    "num_classes = 4\n",
    "net = create_net(num_classes)\n",
    "min_loss = -10000.0\n",
    "last_epoch = -1\n",
    "base_net_lr = lr\n",
    "extra_layers_lr = lr\n",
    "\n",
    "\n",
    "print(\"Base net is frozen..\")\n",
    "freeze_net_layers(net.base_net)\n",
    "params = itertools.chain(net.source_layer_add_ons.parameters(), net.extras.parameters(),\n",
    "                         net.regression_headers.parameters(), net.classification_headers.parameters())\n",
    "params = [\n",
    "    {'params': itertools.chain(\n",
    "        net.source_layer_add_ons.parameters(),\n",
    "        net.extras.parameters()\n",
    "    ), 'lr': extra_layers_lr},\n",
    "    {'params': itertools.chain(\n",
    "        net.regression_headers.parameters(),\n",
    "        net.classification_headers.parameters()\n",
    "    )}\n",
    "]\n",
    "\n",
    "\n",
    "#net.init_from_base_net(base_net)\n",
    "## loading from pretrained model!!\n",
    "pretrained_ssd_dir = '/nethome/jbang36/eva/eva_storage/external/ssd/models/vgg16-ssd-Epoch-149-Loss-3.3744568502269505.pth'\n",
    "\n",
    "net.init_from_pretrained_ssd(pretrained_ssd_dir)\n",
    "\n",
    "\n",
    "net.to(DEVICE)\n",
    "\n",
    "print(\"Done loading to GPU\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Load the rest (optimizer, loss function, etc)\n",
    "\n",
    "criterion = MultiboxLoss(config.priors, iou_threshold=0.5, neg_pos_ratio=3,\n",
    "                         center_variance=0.1, size_variance=0.2, device=DEVICE)\n",
    "optimizer = torch.optim.SGD(params, lr=lr, momentum=0.9,\n",
    "                            weight_decay=5e-4)\n",
    "\n",
    "\n",
    "milestones = [int(v.strip()) for v in \"80,100\".split(\",\")]\n",
    "scheduler = MultiStepLR(optimizer, milestones=milestones,\n",
    "                        gamma=0.1, last_epoch=last_epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filter_path = os.path.join(home_dir, 'filters')\n",
    "loader_path = os.path.join(home_dir, 'loaders')\n",
    "\n",
    "\n",
    "sys.path.append(home_dir)\n",
    "sys.path.append(loader_path)\n",
    "sys.path.append(filter_path)\n",
    "util_path = os.path.join(home_dir, 'others', 'jupyter', 'core')\n",
    "\n",
    "sys.path.append(util_path)\n",
    "\n",
    "from utils import *\n",
    "## I don't think you need to normalize....\n",
    "\n",
    "X_train_norm, X_test_norm, Y_train_dict, Y_test_dict = get_uadetrac()\n",
    "anno_dir = os.path.join(root,'data', 'ua_detrac','small-annotations')\n",
    "boxes_dataset = get_boxes(anno_dir, width = 300, height = 300)\n",
    "y_train = Y_train_dict['vehicle_type']\n",
    "y_test = Y_test_dict['vehicle_type']\n",
    "\n",
    "division = len(X_train_norm)\n",
    "y_train_boxes = boxes_dataset[:division]\n",
    "y_test_boxes = boxes_dataset[division:]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## We need to make val dataset...\n",
    "\n",
    "val_division = int(0.8 * len(X_train_norm))\n",
    "X_val_norm = X_train_norm[val_division:]\n",
    "X_train_norm = X_train_norm[:val_division]\n",
    "y_val_boxes = y_train_boxes[val_division:]\n",
    "y_train_boxes = y_train_boxes[:val_division]\n",
    "y_val = y_train[val_division:]\n",
    "y_train = y_train[:val_division]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = UADataset_lite(transform=train_transform, target_transform=target_transform)\n",
    "X_train = X_train_norm * 255.0\n",
    "X_train = X_train.astype(np.uint8)\n",
    "\n",
    "train_dataset.set_x(X_train)\n",
    "train_dataset.set_y(y_train)\n",
    "train_dataset.set_y_boxes(y_train_boxes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_val = X_val_norm * 255.0\n",
    "X_val = X_val.astype(np.uint8)\n",
    "val_dataset = UADataset_lite(transform=train_transform, target_transform=target_transform)\n",
    "val_dataset.set_x(X_val_norm)\n",
    "val_dataset.set_y(y_val)\n",
    "val_dataset.set_y_boxes(y_val_boxes)\n",
    "\n",
    "X_test = X_test_norm * 255.0\n",
    "X_test = X_test.astype(np.uint8)\n",
    "test_dataset = UADataset_lite(transform=train_transform, target_transform=target_transform)\n",
    "test_dataset.set_x(X_test)\n",
    "test_dataset.set_y(y_test)\n",
    "test_dataset.set_y_boxes(y_test_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## convert to loader \n",
    "batch_size = 24\n",
    "train_loader = DataLoader(train_dataset, batch_size,\n",
    "                          num_workers= 4,\n",
    "                          shuffle=True)\n",
    "\n",
    "val_loader = DataLoader(val_dataset, batch_size,\n",
    "                          num_workers= 4,\n",
    "                          shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## defining train / test functions\n",
    "\n",
    "def train(loader, net, criterion, optimizer, device, debug_steps=100, epoch=-1):\n",
    "    net.train(True)\n",
    "    running_loss = 0.0\n",
    "    running_regression_loss = 0.0\n",
    "    running_classification_loss = 0.0\n",
    "    for i, data in enumerate(loader):\n",
    "        images, boxes, labels = data\n",
    "        images = images.to(device)\n",
    "        boxes = boxes.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        confidence, locations = net(images)\n",
    "        regression_loss, classification_loss = criterion(confidence, locations, labels, boxes)  # TODO CHANGE BOXES\n",
    "        loss = regression_loss + classification_loss\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        running_regression_loss += regression_loss.item()\n",
    "        running_classification_loss += classification_loss.item()\n",
    "        if i and i % debug_steps == 0:\n",
    "            avg_loss = running_loss / debug_steps\n",
    "            avg_reg_loss = running_regression_loss / debug_steps\n",
    "            avg_clf_loss = running_classification_loss / debug_steps\n",
    "            logging.info(\n",
    "                f\"Epoch: {epoch}, Step: {i}, \" +\n",
    "                f\"Average Loss: {avg_loss:.4f}, \" +\n",
    "                f\"Average Regression Loss {avg_reg_loss:.4f}, \" +\n",
    "                f\"Average Classification Loss: {avg_clf_loss:.4f}\"\n",
    "            )\n",
    "            running_loss = 0.0\n",
    "            running_regression_loss = 0.0\n",
    "            running_classification_loss = 0.0\n",
    "\n",
    "\n",
    "def test(loader, net, criterion, device):\n",
    "    net.eval()\n",
    "    running_loss = 0.0\n",
    "    running_regression_loss = 0.0\n",
    "    running_classification_loss = 0.0\n",
    "    num = 0\n",
    "    for _, data in enumerate(loader):\n",
    "        images, boxes, labels = data\n",
    "        images = images.to(device)\n",
    "        boxes = boxes.to(device)\n",
    "        labels = labels.to(device)\n",
    "        num += 1\n",
    "\n",
    "        with torch.no_grad():\n",
    "            confidence, locations = net(images)\n",
    "            regression_loss, classification_loss = criterion(confidence, locations, labels, boxes)\n",
    "            loss = regression_loss + classification_loss\n",
    "\n",
    "        running_loss += loss.item()\n",
    "        running_regression_loss += regression_loss.item()\n",
    "        running_classification_loss += classification_loss.item()\n",
    "    return running_loss / num, running_regression_loss / num, running_classification_loss / num\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## evaluate the model\n",
    "## let's just import utils and do all evaluations here?\n",
    "import time\n",
    "\n",
    "st = time.time()\n",
    "\n",
    "for epoch in range(last_epoch + 1, num_epochs):\n",
    "    scheduler.step()\n",
    "    train(train_loader, net, criterion, optimizer,\n",
    "          device=DEVICE, debug_steps=debug_steps, epoch=epoch)\n",
    "\n",
    "    if epoch % validation_epochs == 0 or epoch == num_epochs - 1:\n",
    "        net.eval()\n",
    "        running_loss = 0.0\n",
    "        running_regression_loss = 0.0\n",
    "        running_classification_loss = 0.0\n",
    "        num = 0\n",
    "        for _, data in enumerate(val_loader):\n",
    "            images, boxes, labels = data\n",
    "            images = images.to(DEVICE)\n",
    "            boxes = boxes.to(DEVICE)\n",
    "            labels = labels.to(DEVICE)\n",
    "            num += 1\n",
    "            with torch.no_grad():\n",
    "                confidence, locations = net(images)\n",
    "                regression_loss, classification_loss = criterion(confidence, locations, labels, boxes)\n",
    "                loss = regression_loss + classification_loss\n",
    "            running_loss += loss.item()\n",
    "            running_regression_loss += regression_loss.item()\n",
    "            running_classification_loss += classification_loss.item()\n",
    "        val_loss = running_loss / num\n",
    "        val_regression_loss = running_regression_loss / num\n",
    "        val_classification_loss = running_regression_loss / num\n",
    "        print(\"epoch\", epoch)\n",
    "        print(\"  Validation Loss: {v:.4f}\".format(v=val_loss))\n",
    "        print(\"  Validatiion Regression Loss: {v:.4f}\".format(v=val_regression_loss))\n",
    "        print(\"  Validation Classification Loss: {v:.4f}\".format(v=val_classification_loss))\n",
    "        \n",
    "        checkpoint_file_name = \"vgg16-ssd:epoch\" + str(epoch)\n",
    "        model_path = os.path.join(checkpoint_folder, checkpoint_file_name)\n",
    "        net.save(model_path)\n",
    "        \n",
    "print(\"Total time to train...\", time.time() - st, \"seconds\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loader = DataLoader(test_dataset, batch_size,\n",
    "                          num_workers= 4,\n",
    "                          shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for _, data in enumerate(test_loader):\n",
    "    images, boxes, labels = data\n",
    "    images = images.to(DEVICE)\n",
    "    boxes = boxes.to(DEVICE)\n",
    "    labels = labels.to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        confidence, locations = net(images)\n",
    "    break\n",
    "    \n",
    "## we now have images, boxes, labels, confidence, locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import vision.utils as ssd_utils\n",
    "## need to convert locations to boxes\n",
    "# I think the center_form_to_corner_form might be wrong??\n",
    "\n",
    "\n",
    "predicted_locations = locations.cpu()\n",
    "\n",
    "predicted_boxes = ssd_utils.box_utils.convert_locations_to_boxes(predicted_locations, config.priors, config.center_variance, config.size_variance)\n",
    "predicted_boxes = ssd_utils.box_utils.center_form_to_corner_form(predicted_boxes)\n",
    "\n",
    "gt_locations = boxes.cpu() ## they have converted boxes to locations\n",
    "gt_boxes = ssd_utils.box_utils.convert_locations_to_boxes(gt_locations, config.priors, config.center_variance, config.size_variance)\n",
    "\n",
    "\n",
    "gt_boxes = ssd_utils.box_utils.center_form_to_corner_form(gt_boxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "For some reason I can't figure out, rectangles are not being drawn on the images\n",
    "\"\"\"\n",
    "\n",
    "n_samples = predicted_boxes.size(0)\n",
    "print(n_samples)\n",
    "image_size = 300\n",
    "color = (255, 0,0)\n",
    "\n",
    "rows = 5\n",
    "cols = 3\n",
    "amp = 1\n",
    "\n",
    "fig, axes = plt.subplots(rows, cols, figsize = (30*amp,30*amp))\n",
    "\n",
    "\n",
    "for i in range(n_samples):\n",
    "    img_tmp = np.ndarray(shape = (300,300,3), dtype = np.uint8)\n",
    "    image = images_cpu[i]\n",
    "    predicted_boxes_reshaped = predicted_boxes[i][pos_mask[i], :]\n",
    "    gt_boxes_reshaped = gt_boxes[i][pos_mask[i], :]\n",
    "    \n",
    "    \n",
    "    image = image.permute(1,2,0)\n",
    "    image_np = image.numpy().astype(np.uint8)\n",
    "    image_cp = np.copy(image_np)\n",
    "    \n",
    "    \n",
    "    axes[i,0].imshow(image_np)\n",
    "    n_rects = predicted_boxes_reshaped.size(0)\n",
    "    pbr = (predicted_boxes_reshaped.numpy() * image_size).astype(np.uint8)\n",
    "    gbr = (gt_boxes_reshaped.numpy() * image_size).astype(np.uint8)\n",
    "    for j in range(n_rects):\n",
    "        #should be left, top, right, bottom\n",
    "        # let's draw the ground boxes to be sure\n",
    "        \n",
    "        cv2.rectangle(image_np, (pbr[j][0], pbr[j][1]), (pbr[j][2], pbr[j][3]), color, 2)\n",
    "            \n",
    "    axes[i,1].imshow(image_np)\n",
    "    \n",
    "    n_rects = gt_boxes_reshaped.size(0)\n",
    "    for j in range(n_rects):\n",
    "        cv2.rectangle(image_cp, (gbr[j][0], gbr[j][1]), (gbr[j][2], gbr[j][3]), color, 2)\n",
    "        \n",
    "    \n",
    "    axes[i,2].imshow(image_cp)\n",
    "    \n",
    "    if i == rows - 1:\n",
    "        break\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## we want to do things image by image... let's organize the boxes into list\n",
    "predicted_boxes_list = []\n",
    "gt_boxes_list = []\n",
    "\n",
    "\n",
    "\n",
    "pos_mask = labels > 0\n",
    "predicted_boxes_reshaped = predicted_boxes[pos_mask, :]\n",
    "print(predicted_boxes_reshaped.size())\n",
    "gt_boxes_reshaped = gt_boxes[pos_mask, :]\n",
    "print(gt_boxes_reshaped.size())\n",
    "## I guess all we need is the statistics so convert them all and then see\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Evaluation\n",
    "\n",
    "## do code evaluation...\n",
    "\n",
    "all_ground_boxes = []\n",
    "all_proposed_boxes = []\n",
    "all_confidence = []\n",
    "all_labels = []\n",
    "all_images = []\n",
    "\n",
    "for _, data in enumerate(test_loader):\n",
    "    images, boxes, labels = data\n",
    "    images = images.to(DEVICE)\n",
    "    boxes = boxes.to(DEVICE)\n",
    "    labels = labels.to(DEVICE)\n",
    "    with torch.no_grad():\n",
    "        confidence, locations = net(images)\n",
    "        all_proposed_boxes.append(locations)\n",
    "        all_confidence.append(confidence)\n",
    "        all_labels.append(labels)\n",
    "        all_ground_boxes.append(boxes)\n",
    "        all_images.append(images)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# each element in this array will be the batch result\n",
    "\n",
    "assert(len(all_proposed_boxes) == len(all_confidence))\n",
    "assert(len(all_proposed_boxes) == len(all_labels))\n",
    "assert(len(all_proposed_boxes) == len(all_ground_boxes))\n",
    "assert(len(all_proposed_boxes) == len(all_images))\n",
    "\n",
    "def compute_stats(gt_boxes, proposed_boxes, iou=0.5):\n",
    "    assert(gt_boxes.size() == proposed_boxes.size())\n",
    "    iou_list = ssd_utils.box_utils.iou_of(gt_boxes, proposed_boxes)\n",
    "    tmp = iou_list > iou\n",
    "    \n",
    "    tp = torch.sum(iou_list > iou)\n",
    "    \n",
    "    return tp.item(), tmp.size()\n",
    "\n",
    "import vision.utils as ssd_utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tp_all = 0\n",
    "boxes_all = 0\n",
    "\n",
    "for i, images in enumerate(all_images):\n",
    "    predicted_locations = all_proposed_boxes[i].cpu()\n",
    "    predicted_boxes = ssd_utils.box_utils.convert_locations_to_boxes(predicted_locations, config.priors, config.center_variance, config.size_variance)\n",
    "    predicted_boxes = ssd_utils.box_utils.center_form_to_corner_form(predicted_boxes)\n",
    "\n",
    "    gt_locations = all_ground_boxes[i].cpu()\n",
    "    gt_boxes = ssd_utils.box_utils.convert_locations_to_boxes(gt_locations, config.priors, config.center_variance, config.size_variance)\n",
    "    gt_boxes = ssd_utils.box_utils.center_form_to_corner_form(gt_boxes)\n",
    "\n",
    "    labels = all_labels[i]\n",
    "    pos_mask = labels > 0\n",
    "    predicted_boxes_reshaped = predicted_boxes[pos_mask, :]\n",
    "    gt_boxes_reshaped = gt_boxes[pos_mask, :]\n",
    "    tp, all_size = compute_stats(gt_boxes_reshaped, predicted_boxes_reshaped)\n",
    "    tp_all += tp\n",
    "    boxes_all += all_size[0]\n",
    "    \n",
    "print(1.0 * tp_all / boxes_all)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## looking at the images, I don't think this is a good measure \n",
    "## because it creates multiple boxes for each object...\n",
    "## so we need to figure out a way to eliminate recurring boxes\n",
    "# let's try evaluation method that is already implemented from eval_ssd.py\n",
    "\n",
    "from vision.ssd.vgg_ssd import create_vgg_ssd, create_vgg_ssd_predictor\n",
    "\n",
    "\n",
    "predictor = create_vgg_ssd_predictor(net, nms_method=\"hard\", device=DEVICE)\n",
    "results = []\n",
    "dataset = test_dataset\n",
    "for i in range(len(dataset)):\n",
    "    print(\"process image\", i)\n",
    "    timer.start(\"Load Image\")\n",
    "    image = dataset.get_image(i)\n",
    "    print(\"Load Image: {:4f} seconds.\".format(timer.end(\"Load Image\")))\n",
    "    timer.start(\"Predict\")\n",
    "    boxes, labels, probs = predictor.predict(image)\n",
    "    print(\"Prediction: {:4f} seconds.\".format(timer.end(\"Predict\")))\n",
    "    indexes = torch.ones(labels.size(0), 1, dtype=torch.float32) * i\n",
    "    results.append(torch.cat([\n",
    "        indexes.reshape(-1, 1),\n",
    "        labels.reshape(-1, 1).float(),\n",
    "        probs.reshape(-1, 1),\n",
    "        boxes   # + 1.0 matlab's indexes start from 1\n",
    "    ], dim=1))\n",
    "    \n",
    "results = torch.cat(results)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class_names = ['car', 'bus', 'others', 'van']\n",
    "\n",
    "for class_index, class_name in enumerate(class_names):\n",
    "    if class_index == 0: continue  # ignore background\n",
    "    sub = results[results[:, 1] == class_index, :]\n",
    "    for i in range(sub.size(0)):\n",
    "        prob_box = sub[i, 2:].numpy()\n",
    "        print(sub[i,2:])  \n",
    "        print(int(sub[i,0]))\n",
    "        #image_id = dataset.ids[int(sub[i, 0])]\n",
    "        image_id = \"0\"\n",
    "        print(\n",
    "            image_id + \" \" + \" \".join([str(v) for v in prob_box])\n",
    "        )\n",
    "        break\n",
    "aps = []\n",
    "    \n",
    "\n",
    "print(\"\\n\\nAverage Precision Per-class:\")\n",
    "for class_index, class_name in enumerate(class_names):\n",
    "    iou_threshold = 0.5\n",
    "    use_2007_metric = True\n",
    "    ap = compute_average_precision_per_class(\n",
    "        true_case_stat[class_index],\n",
    "        all_gb_boxes[class_index],\n",
    "        all_difficult_cases[class_index],\n",
    "        prediction_path,\n",
    "        iou_threshold, \n",
    "        use_2007_metric\n",
    "    )\n",
    "    aps.append(ap)\n",
    "    \n",
    "print(f\"\\nAverage Precision Across All Classes:{sum(aps)/len(aps)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to accumulate the results..\n",
    "# also if there are squares that are being used multiple times, we need to prevent that bc it's not fair to detect easy ones multiple times to get good numbers\n",
    "# adapt this some how...\n",
    "## TODO! This function is not finished...\n",
    "\n",
    "matched = set()\n",
    "for i, image_batch in enumerate(all_images):\n",
    "    predicted_locations = all_proposed_boxes[i].cpu()\n",
    "    predicted_boxes = ssd_utils.box_utils.convert_locations_to_boxes(predicted_locations, config.priors, config.center_variance, config.size_variance)\n",
    "    predicted_boxes = ssd_utils.box_utils.center_form_to_corner_form(predicted_boxes)\n",
    "\n",
    "    gt_locations = all_ground_boxes[i].cpu()\n",
    "    gt_boxes = ssd_utils.box_utils.convert_locations_to_boxes(gt_locations, config.priors, config.center_variance, config.size_variance)\n",
    "    gt_boxes = ssd_utils.box_utils.center_form_to_corner_form(gt_boxes)\n",
    "    labels = all_labels[i]\n",
    "    \n",
    "    \n",
    "    for j in range(image_batch.size(0)):\n",
    "        image = image_batch[j]\n",
    "        labels_frame = labels[j]\n",
    "        gt_boxes_frame = gt_boxes[j]\n",
    "        predicted_boxes_frame = predicted_boxes[j]\n",
    "        \n",
    "        pos_mask = labels_frame > 0\n",
    "        predicted_boxes_reshaped = predicted_boxes[pos_mask, :]\n",
    "        gt_boxes_reshaped = gt_boxes[pos_mask, :]\n",
    "        tp, all_size = compute_stats(gt_boxes_reshaped, predicted_boxes_reshaped)\n",
    "        tp_all += tp\n",
    "        boxes_all += all_size[0]\n",
    "        \n",
    "for i, image_id in enumerate(image_ids):\n",
    "    box = boxes[i]\n",
    "    if image_id not in gt_boxes:\n",
    "        false_positive[i] = 1\n",
    "        continue\n",
    "\n",
    "    gt_box = gt_boxes[image_id]\n",
    "    ious = box_utils.iou_of(box, gt_box)\n",
    "    max_iou = torch.max(ious).item() \n",
    "    # the only reason you can do this is if you assume there is one box per frame\n",
    "    # however, uadetrac does not have one frame, it has multiple frames. \n",
    "    # we need to look into the transformer to see how everything changes\n",
    "    max_arg = torch.argmax(ious).item()\n",
    "    if max_iou > iou_threshold:\n",
    "        if difficult_cases[image_id][max_arg] == 0:\n",
    "            if (image_id, max_arg) not in matched:\n",
    "                true_positive[i] = 1\n",
    "                matched.add((image_id, max_arg))\n",
    "            else:\n",
    "                false_positive[i] = 1\n",
    "    else:\n",
    "        false_positive[i] = 1\n",
    "\n",
    "    true_positive = true_positive.cumsum()\n",
    "    false_positive = false_positive.cumsum()\n",
    "    precision = true_positive / (true_positive + false_positive)\n",
    "    recall = true_positive / num_true_cases\n",
    "    if use_2007_metric:\n",
    "        return measurements.compute_voc2007_average_precision(precision, recall)\n",
    "    else:\n",
    "        return measurements.compute_average_precision(precision, recall)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = all_labels[0]\n",
    "predicted_locations = all_proposed_boxes[0]\n",
    "gt_locations = all_ground_boxes[0]\n",
    "\n",
    "import vision.utils as ssd_utils\n",
    "## need to convert locations to boxes\n",
    "\n",
    "predicted_locations = all_proposed_boxes[0].cpu()\n",
    "predicted_boxes = ssd_utils.box_utils.convert_locations_to_boxes(predicted_locations, config.priors, config.center_variance, config.size_variance)\n",
    "predicted_boxes = ssd_utils.box_utils.center_form_to_corner_form(predicted_boxes)\n",
    "\n",
    "gt_locations = all_ground_boxes[0].cpu()\n",
    "gt_boxes = ssd_utils.box_utils.convert_locations_to_boxes(gt_locations, config.priors, config.center_variance, config.size_variance)\n",
    "gt_boxes = ssd_utils.box_utils.center_form_to_corner_form(gt_boxes)\n",
    "\n",
    "\n",
    "pos_mask = labels > 0\n",
    "predicted_boxes_reshaped = predicted_boxes[pos_mask, :]\n",
    "print(predicted_boxes_reshaped.size())\n",
    "gt_boxes_reshaped = gt_boxes[pos_mask, :]\n",
    "print(gt_boxes_reshaped.size())\n",
    "## I guess all we need is the statistics so convert them all and then see\n",
    "\n",
    "### okay now we have to start matching??\n",
    "### -> I don't think we need to manually match\n",
    "### -> Let's just calculate the final score first to see what's up\n",
    "\n",
    "def compute_stats(gt_boxes, proposed_boxes, iou=0.5):\n",
    "    assert(gt_boxes.size() == proposed_boxes.size())\n",
    "    iou_list = ssd_utils.box_utils.iou_of(gt_boxes, predicted_boxes)\n",
    "    tmp = iou_list > iou\n",
    "    print(tmp)\n",
    "    \n",
    "    tp = torch.sum(iou_list > iou)\n",
    "    return tp\n",
    "\n",
    "print(compute_stats(gt_boxes, predicted_boxes))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "### okay now we have to start matching??\n",
    "### -> I don't think we need to manually match\n",
    "### -> Let's just calculate the final score first to see what's up\n",
    "\n",
    "def compute_stats(gt_boxes, proposed_boxes, iou=0.5):\n",
    "    assert(gt_boxes.size() == proposed_boxes.size())\n",
    "    iou_list = ssd_utils.box_utils.iou_of(gt_boxes, predicted_boxes)\n",
    "    tmp = iou_list > iou\n",
    "    print(tmp)\n",
    "    \n",
    "    tp = torch.sum(iou_list > iou)\n",
    "    return tp\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(smooth_l1_loss)\n",
    "print(num_pos)\n",
    "print(predicted_locations.size())\n",
    "print(gt_locations.size())\n",
    "\n",
    "## probably make a converting function....\n",
    "# proposed_boxes = convertssd2ml(all_locations)\n",
    "\n",
    "### after training on UA-detrac, let's do some evaluation!\n",
    "## Use the functions available from utils\n",
    "\n",
    "precision, recall = corloc(test_boxes, proposed_boxes, iou = 0.5)\n",
    "print(precision)\n",
    "print(recall)\n",
    "\n",
    "### after filtering\n",
    "filtered_test_boxes = filter_ground_truth(test_boxes)\n",
    "\n",
    "precision, recall = corloc(filtered_test_boxes, proposed_boxes, iou = 0.5)\n",
    "print(precision)\n",
    "print(recall)\n",
    "\n",
    "### visualization\n",
    "\n",
    "from utils import *\n",
    "\n",
    "rows = 5\n",
    "cols = 3\n",
    "size = 30\n",
    "n_samples = test_images.shape[0]\n",
    "fig, axes = plt.subplots(rows, cols, figsize = (size*cols, size*rows), sharex = True, sharey = True)\n",
    "\n",
    "for i in range(rows):\n",
    "    random_index = random.randint(0, n_samples)\n",
    "    axes[i, 0].imshow(test_images[random_index])\n",
    "    cv_patches = ml2cv_patches(filtered_test_boxes[random_index])\n",
    "    ground_image = draw_patches(test_images[random_index], cv_patches)\n",
    "    axes[i, 1].imshow(ground_image)\n",
    "    cv_patches2 = ml2cv_patches(proposed_boxes[random_index])\n",
    "    proposed_image = draw_patches(test_images[random_index], cv_patches2)\n",
    "    axes[i, 2].imshow(proposed_image)\n",
    "    print(\"row\", i)\n",
    "    precision, recall = corloc([filtered_test_boxes[random_index]], [proposed_boxes[random_index]], iou = 0.5)\n",
    "    print(\"  precision:\", precision, \" recall:\", recall)\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
